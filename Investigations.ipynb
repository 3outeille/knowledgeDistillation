{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and investigation\n",
    "Generally one can consider two settings that could be interesting to investigate:\n",
    "- Decaying the impact of the teacher model with the epochs. As the student becomes better, the hints might become a restriction and the student might overfit to the teacher.\n",
    "- Despite the teacher being better than the student, it still creates errors and adapting the tranferred knowledge to only include those samples that the teacher predicts correctly, might allow the student to more freely learn what the teacher can not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from distillation.hintonDistiller import HintonDistiller\n",
    "from distillation.utils import CNN, Accuracy\n",
    "from torchvision import datasets, transforms\n",
    "from trainer.baseTrainer import BaseTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random models and distiller\n",
    "imgSize = (1, 28, 28)\n",
    "batchSize = 256\n",
    "\n",
    "# Prepare data\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transform\n",
    "                  ),\n",
    "    batch_size=batchSize)\n",
    "\n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data/',\n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transform\n",
    "                  ),\n",
    "    batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train teacher on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saves checkpoint in checkpoint/train/20200908-131208\n",
      "\n",
      "========= Training =========\n",
      "Epoch:   1/5\t Train/Loss: 0.440\t Train/Metric: 0.886\t Valid/Loss: 0.211\t Valid/Metric: 0.939\n",
      "Epoch:   2/5\t Train/Loss: 0.176\t Train/Metric: 0.952\t Valid/Loss: 0.157\t Valid/Metric: 0.955\n",
      "Epoch:   3/5\t Train/Loss: 0.136\t Train/Metric: 0.963\t Valid/Loss: 0.129\t Valid/Metric: 0.964\n",
      "Epoch:   4/5\t Train/Loss: 0.114\t Train/Metric: 0.970\t Valid/Loss: 0.113\t Valid/Metric: 0.967\n",
      "Epoch:   5/5\t Train/Loss: 0.099\t Train/Metric: 0.975\t Valid/Loss: 0.101\t Valid/Metric: 0.969\n"
     ]
    }
   ],
   "source": [
    "teacher = CNN(imgSize, 64)\n",
    "\n",
    "# Initialize objectives and optimizer\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(teacher.parameters(), lr=1e-2)\n",
    "metric = Accuracy(OH=False)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = BaseTrainer()\n",
    "\n",
    "# Load state if checkpoint is provided otherwise .load_state merely returns 1 as startEpoch\n",
    "checkpoint = None\n",
    "startEpoch = trainer.load_state(checkpoint, teacher, optimizer)\n",
    "\n",
    "# Construct checkpoint directory\n",
    "trainer.save(0, teacher, optimizer, {}, subDirectory='train')\n",
    "print('Saves checkpoint in {:s}'.format(trainer.checkpointDir))\n",
    "\n",
    "print('\\n========= Training =========')\n",
    "for epoch in range(startEpoch, EPOCHS+1):\n",
    "    # Training step for one full epoch\n",
    "    trainMetrics = trainer.train_step(model=teacher,\n",
    "                                      dataloader=trainloader,\n",
    "                                      objective=objective,\n",
    "                                      metric=metric,\n",
    "                                      optimizer=optimizer)\n",
    "        \n",
    "    # Validation step for one full epoch\n",
    "    validMetrics = trainer.validate(model=teacher,\n",
    "                                    dataloader=validloader,\n",
    "                                    objective=objective,\n",
    "                                    metric=metric)\n",
    "\n",
    "    metrics = {**trainMetrics, **validMetrics}\n",
    "\n",
    "    # Save teacher\n",
    "    trainer.save(epoch, teacher, optimizer, metrics, subDirectory='train')\n",
    "        \n",
    "    # Print epoch performance\n",
    "    trainer.print_epoch(epoch, EPOCHS, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distill with Hinton KD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = CNN(imgSize, 32)\n",
    "distiller = HintonDistiller(alpha=0.1,\n",
    "                            studentLayer=-2,\n",
    "                            teacherLayer=-2)\n",
    "\n",
    "# Initialize objectives and optimizer\n",
    "objective = nn.CrossEntropyLoss()\n",
    "distillObjective = nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=1e-2)\n",
    "\n",
    "# Load state if checkpoint is provided\n",
    "checkpoint = None\n",
    "startEpoch = distiller.load_state(checkpoint, student, teacher, optimizer)\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(startEpoch, epochs+1):\n",
    "        # Training step for one full epoch\n",
    "        trainMetrics = distiller.train_step(student=student,\n",
    "                                            teacher=teacher,\n",
    "                                            dataloader=trainloader,\n",
    "                                            optimizer=optimizer,\n",
    "                                            objective=objective,\n",
    "                                            distillObjective=distillObjective)\n",
    "        \n",
    "        # Validation step for one full epoch\n",
    "        validMetrics = distiller.validate(student=student,\n",
    "                                          dataloader=validloader,\n",
    "                                          objective=objective)\n",
    "        metrics = {**trainMetrics, **validMetrics}\n",
    "\n",
    "        # Save model\n",
    "        distiller.save(epoch, student, teacher, optimizer)\n",
    "        \n",
    "        # Print epoch performance\n",
    "        distiller.print_epoch(epoch, epochs, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
