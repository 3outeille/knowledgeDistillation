{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/15\t Loss/Pseudo: 0.019\t Loss/Student: 2.113\t Valid/Loss: 4.464\t Valid/Metric: 0.005\n",
      "Epoch:   2/15\t Loss/Pseudo: 0.339\t Loss/Student: 2.922\t Valid/Loss: 4.486\t Valid/Metric: 0.027\n",
      "Epoch:   3/15\t Loss/Pseudo: 0.416\t Loss/Student: 2.300\t Valid/Loss: 4.381\t Valid/Metric: 0.077\n",
      "Epoch:   4/15\t Loss/Pseudo: 0.318\t Loss/Student: 2.183\t Valid/Loss: 4.858\t Valid/Metric: 0.049\n",
      "Epoch:   5/15\t Loss/Pseudo: 0.435\t Loss/Student: 2.224\t Valid/Loss: 4.717\t Valid/Metric: 0.023\n",
      "Epoch:   6/15\t Loss/Pseudo: 0.411\t Loss/Student: 2.143\t Valid/Loss: 3.998\t Valid/Metric: 0.038\n",
      "Epoch:   7/15\t Loss/Pseudo: 0.377\t Loss/Student: 1.616\t Valid/Loss: 4.438\t Valid/Metric: 0.058\n",
      "Epoch:   8/15\t Loss/Pseudo: 0.480\t Loss/Student: 2.065\t Valid/Loss: 4.566\t Valid/Metric: 0.001\n",
      "Epoch:   9/15\t Loss/Pseudo: 0.373\t Loss/Student: 1.750\t Valid/Loss: 4.605\t Valid/Metric: 0.031\n",
      "Epoch:  10/15\t Loss/Pseudo: 0.488\t Loss/Student: 1.608\t Valid/Loss: 4.647\t Valid/Metric: 0.032\n",
      "Epoch:  11/15\t Loss/Pseudo: 0.447\t Loss/Student: 1.450\t Valid/Loss: 4.829\t Valid/Metric: 0.000\n",
      "Epoch:  12/15\t Loss/Pseudo: 0.506\t Loss/Student: 1.357\t Valid/Loss: 4.966\t Valid/Metric: 0.043\n",
      "Epoch:  13/15\t Loss/Pseudo: 0.470\t Loss/Student: 1.384\t Valid/Loss: 4.814\t Valid/Metric: 0.004\n",
      "Epoch:  14/15\t Loss/Pseudo: 0.587\t Loss/Student: 1.287\t Valid/Loss: 4.735\t Valid/Metric: 0.076\n",
      "Epoch:  15/15\t Loss/Pseudo: 0.562\t Loss/Student: 1.474\t Valid/Loss: 4.893\t Valid/Metric: 0.006\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from distillation.datafreeDistiller import DataFreeDistiller\n",
    "from distillation.utils import PseudoDataset, CNN, Generator\n",
    "from distillation.datasetDistiller import DatasetDistiller\n",
    "from distillation.utils import SigmoidScaler\n",
    "\n",
    "# Initialize random models and distiller\n",
    "imgSize = (3, 32, 32)\n",
    "noiseDim = 100\n",
    "student = CNN(imgSize, 64)\n",
    "teacher = CNN(imgSize, 64)\n",
    "distiller = DatasetDistiller(pseudoIters=3,\n",
    "                             studentIters=2,\n",
    "                             pseudoLR=1e-1,\n",
    "                             scaler=SigmoidScaler((0,1)),\n",
    "                             batchSize=64,\n",
    "                             pseudoSize=imgSize)\n",
    "\n",
    "# Initialize objectives and optimizer\n",
    "objective = nn.KLDivLoss(reduction='batchmean')\n",
    "validObjective = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.1)\n",
    "\n",
    "# Pseudo dataset and dataloader \n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    PseudoDataset(size=imgSize),\n",
    "    batch_size=512,\n",
    "    shuffle=True)\n",
    "\n",
    "# Load state if checkpoint is provided\n",
    "checkpoint = None\n",
    "startEpoch = distiller.load_state(checkpoint, student, teacher, optimizer)\n",
    "epochs = 15\n",
    "\n",
    "# Construct tensorboard logger\n",
    "distiller.init_tensorboard_logger()\n",
    "\n",
    "for epoch in range(startEpoch, epochs+1):\n",
    "        # Training step for one full epoch\n",
    "        trainMetrics = distiller.train_step(student=student,\n",
    "                                            teacher=teacher,\n",
    "                                            dataloader=None,\n",
    "                                            optimizer=optimizer,\n",
    "                                            objective=objective,\n",
    "                                            distillObjective=None)\n",
    "        \n",
    "        # Validation step for one full epoch\n",
    "        validMetrics = distiller.validate(student=student,\n",
    "                                          dataloader=validloader,\n",
    "                                          objective=validObjective)\n",
    "        metrics = {**trainMetrics, **validMetrics}\n",
    "        \n",
    "        # Log to tensorbard\n",
    "        distiller.log(epoch, metrics)\n",
    "\n",
    "        # Save model\n",
    "        distiller.save(epoch, student, teacher, optimizer)\n",
    "        \n",
    "        # Print epoch performance\n",
    "        distiller.print_epoch(epoch, epochs, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1/15\t Loss/Pseudo: 0.019\t Loss/Student: 2.177\t Valid/Loss: 4.061\t Valid/Metric: 0.081\n",
      "Epoch:   2/15\t Loss/Pseudo: 0.267\t Loss/Student: 3.182\t Valid/Loss: 4.766\t Valid/Metric: 0.003\n",
      "Epoch:   3/15\t Loss/Pseudo: 0.338\t Loss/Student: 2.260\t Valid/Loss: 4.315\t Valid/Metric: 0.056\n",
      "Epoch:   4/15\t Loss/Pseudo: 0.342\t Loss/Student: 2.396\t Valid/Loss: 4.540\t Valid/Metric: 0.001\n",
      "Epoch:   5/15\t Loss/Pseudo: 0.329\t Loss/Student: 2.095\t Valid/Loss: 4.402\t Valid/Metric: 0.072\n",
      "Epoch:   6/15\t Loss/Pseudo: 0.303\t Loss/Student: 1.921\t Valid/Loss: 4.391\t Valid/Metric: 0.088\n",
      "Epoch:   7/15\t Loss/Pseudo: 0.379\t Loss/Student: 1.965\t Valid/Loss: 4.452\t Valid/Metric: 0.018\n",
      "Epoch:   8/15\t Loss/Pseudo: 0.375\t Loss/Student: 1.849\t Valid/Loss: 4.541\t Valid/Metric: 0.014\n",
      "Epoch:   9/15\t Loss/Pseudo: 0.394\t Loss/Student: 2.082\t Valid/Loss: 4.922\t Valid/Metric: 0.010\n",
      "Epoch:  10/15\t Loss/Pseudo: 0.439\t Loss/Student: 1.509\t Valid/Loss: 4.253\t Valid/Metric: 0.001\n",
      "Epoch:  11/15\t Loss/Pseudo: 0.469\t Loss/Student: 1.397\t Valid/Loss: 4.519\t Valid/Metric: 0.006\n",
      "Epoch:  12/15\t Loss/Pseudo: 0.487\t Loss/Student: 1.542\t Valid/Loss: 4.389\t Valid/Metric: 0.032\n",
      "Epoch:  13/15\t Loss/Pseudo: 0.443\t Loss/Student: 1.589\t Valid/Loss: 4.925\t Valid/Metric: 0.021\n",
      "Epoch:  14/15\t Loss/Pseudo: 0.533\t Loss/Student: 1.198\t Valid/Loss: 4.618\t Valid/Metric: 0.002\n",
      "Epoch:  15/15\t Loss/Pseudo: 0.568\t Loss/Student: 0.977\t Valid/Loss: 4.004\t Valid/Metric: 0.006\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from distillation.datasetDistiller import DatasetDistiller\n",
    "from distillation.utils import PseudoDataset, CNN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize random models and distiller\n",
    "imgSize = (3, 32, 32)\n",
    "student = CNN(imgSize, 64)\n",
    "teacher = CNN(imgSize, 64)\n",
    "distiller = DatasetDistiller(pseudoIters=3,\n",
    "                             studentIters=2,\n",
    "                             pseudoLR=1e-1,\n",
    "                             scaler=SigmoidScaler((0,1)),\n",
    "                             batchSize=64,\n",
    "                             pseudoSize=imgSize)\n",
    "\n",
    "# Initialize objectives and optimizer\n",
    "objective = nn.KLDivLoss(reduction='batchmean')\n",
    "validObjective = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.1)\n",
    "\n",
    "# Pseudo dataset and dataloader \n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    PseudoDataset(size=imgSize),\n",
    "    batch_size=512,\n",
    "    shuffle=True)\n",
    "\n",
    "# Load state if checkpoint is provided\n",
    "checkpoint = None\n",
    "startEpoch = distiller.load_state(checkpoint, student, teacher, optimizer)\n",
    "epochs = 15\n",
    "\n",
    "# Construct tensorboard logger\n",
    "distiller.init_tensorboard_logger()\n",
    "\n",
    "for epoch in range(startEpoch, epochs+1):\n",
    "        # Training step for one full epoch\n",
    "        trainMetrics = distiller.train_step(student=student,\n",
    "                                            teacher=teacher,\n",
    "                                            dataloader=None,\n",
    "                                            optimizer=optimizer,\n",
    "                                            objective=objective,\n",
    "                                            distillObjective=None)\n",
    "        \n",
    "        # Validation step for one full epoch\n",
    "        validMetrics = distiller.validate(student=student,\n",
    "                                          dataloader=validloader,\n",
    "                                          objective=validObjective)\n",
    "        metrics = {**trainMetrics, **validMetrics}\n",
    "        \n",
    "        # Log to tensorbard\n",
    "        distiller.log(epoch, metrics)\n",
    "\n",
    "        # Save model\n",
    "        distiller.save(epoch, student, teacher, optimizer)\n",
    "        \n",
    "        # Print epoch performance\n",
    "        distiller.print_epoch(epoch, epochs, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch:   1/15\t Loss/Pseudo: 0.030\t Loss/Student: 14.693\t Valid/Loss: 8.820\t Valid/Metric: 0.100\n",
      "Epoch:   2/15\t Loss/Pseudo: 2.779\t Loss/Student: 13.850\t Valid/Loss: 8.825\t Valid/Metric: 0.100\n",
      "Epoch:   3/15\t Loss/Pseudo: 2.748\t Loss/Student: 14.720\t Valid/Loss: 8.051\t Valid/Metric: 0.100\n",
      "Epoch:   4/15\t Loss/Pseudo: 2.410\t Loss/Student: 14.289\t Valid/Loss: 8.543\t Valid/Metric: 0.100\n",
      "Epoch:   5/15\t Loss/Pseudo: 2.838\t Loss/Student: 12.676\t Valid/Loss: 9.321\t Valid/Metric: 0.103\n",
      "Epoch:   6/15\t Loss/Pseudo: 2.859\t Loss/Student: 9.734\t Valid/Loss: 11.452\t Valid/Metric: 0.100\n",
      "Epoch:   7/15\t Loss/Pseudo: 2.428\t Loss/Student: 10.201\t Valid/Loss: 11.617\t Valid/Metric: 0.100\n",
      "Epoch:   8/15\t Loss/Pseudo: 3.046\t Loss/Student: 12.765\t Valid/Loss: 11.770\t Valid/Metric: 0.100\n",
      "Epoch:   9/15\t Loss/Pseudo: 3.667\t Loss/Student: 11.770\t Valid/Loss: 9.640\t Valid/Metric: 0.100\n",
      "Epoch:  10/15\t Loss/Pseudo: 2.771\t Loss/Student: 7.450\t Valid/Loss: 11.943\t Valid/Metric: 0.100\n",
      "Epoch:  11/15\t Loss/Pseudo: 3.532\t Loss/Student: 8.389\t Valid/Loss: 12.290\t Valid/Metric: 0.100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b54d3697a4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m         validMetrics = distiller.validate(student=student,\n\u001b[1;32m     84\u001b[0m                                           \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                                           objective=validObjective)\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrainMetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mvalidMetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/AU/PhD/scripts/knowledgeDistillation/distillation/datasetDistiller.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, student, dataloader, objective, OneHot)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;31m# Calculate logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0msLogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from distillation.datasetDistiller import DatasetDistiller\n",
    "from distillation.utils import PseudoDataset, CNN\n",
    "from torchvision import models\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Scaler\n",
    "class ScaleWrapper(nn.Module):\n",
    "    def __init__(self, interval):\n",
    "        super(ScaleWrapper, self).__init__()\n",
    "        \n",
    "    def _scaler(self, x):\n",
    "        raise NotImplementedError('_scaler should be implemented in descendent of ScaleWrap class!')\n",
    "        \n",
    "    def __call__(self, x):        \n",
    "        # Apply scaler and return to interval scale.\n",
    "        return (self.interval[1]-self.interval[0])*self._scaler(x) + self.interval[0]\n",
    "        \n",
    "class SigmoidScaler(ScaleWrapper):\n",
    "    def __init__(self, interval, p=2.463):\n",
    "        super(SigmoidScaler, self).__init__(interval)\n",
    "        self.p = p\n",
    "        self.interval = interval\n",
    "        self.scale = (self.interval[1] - self.interval[0])/2\n",
    "        self.center = (self.interval[0] + self.interval[1])/2\n",
    "        \n",
    "    def _scaler(self, x):\n",
    "        return torch.sigmoid(self.p/self.scale * (x - self.center))\n",
    "\n",
    "\n",
    "# Initialize random models and distiller\n",
    "imgSize = (3, 32, 32)\n",
    "student = CNN(imgSize, 10)\n",
    "teacher = models.alexnet(pretrained=True)\n",
    "teacher.features[0] = nn.Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3))\n",
    "teacher.classifier[6] = nn.Linear(4096, 10)\n",
    "distiller = DatasetDistiller(pseudoIters=3,\n",
    "                             studentIters=2,\n",
    "                             pseudoLR=1e-2,\n",
    "                             scaler=SigmoidScaler((0,1)),\n",
    "                             batchSize=10,\n",
    "                             pseudoSize=imgSize)\n",
    "\n",
    "# Initialize objectives and optimizer\n",
    "objective = nn.KLDivLoss(reduction='batchmean')\n",
    "validObjective = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.1)\n",
    "\n",
    "# Pseudo dataset and dataloader\n",
    "validloader = torch.utils.data.DataLoader( \n",
    "            datasets.CIFAR10('data',\n",
    "                             train=False,\n",
    "                             download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.RandomCrop(32, padding=4),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                             ])),\n",
    "            batch_size=8,\n",
    "            shuffle=True,\n",
    "            num_workers=4)\n",
    "\n",
    "# Load state if checkpoint is provided\n",
    "checkpoint = None\n",
    "startEpoch = distiller.load_state(checkpoint, student, teacher, optimizer)\n",
    "epochs = 15\n",
    "\n",
    "# Construct tensorboard logger\n",
    "distiller.init_tensorboard_logger()\n",
    "\n",
    "for epoch in range(startEpoch, epochs+1):\n",
    "        # Training step for one full epoch\n",
    "        trainMetrics = distiller.train_step(student=student,\n",
    "                                            teacher=teacher,\n",
    "                                            dataloader=None,\n",
    "                                            optimizer=optimizer,\n",
    "                                            objective=objective,\n",
    "                                            distillObjective=None)\n",
    "        \n",
    "        # Validation step for one full epoch\n",
    "        validMetrics = distiller.validate(student=student,\n",
    "                                          dataloader=validloader,\n",
    "                                          objective=validObjective)\n",
    "        \n",
    "        metrics = {**trainMetrics, **validMetrics}\n",
    "        \n",
    "        # Log to tensorbard\n",
    "        distiller.log(epoch, metrics)\n",
    "\n",
    "        # Save model\n",
    "        distiller.save(epoch, student, teacher, optimizer)\n",
    "        \n",
    "        # Print epoch performance\n",
    "        distiller.print_epoch(epoch, epochs, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher.features[0] = nn.Conv2d(3, 64, kernel_size=(2, 2), stride=(1, 1), padding=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher(torch.rand((8,3,32,32))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
